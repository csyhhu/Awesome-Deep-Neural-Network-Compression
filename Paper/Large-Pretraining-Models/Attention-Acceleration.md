# Linear Attention
Linear attention aims at reducing computation complexity in attention from $O(N^2)$ to $O(N)$:

- Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention
- Transformer Dissection: A Unified Understanding of Transformer's Attention via the Lens of Kernel
- Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention
- Exact Conversion of In-Context Learning to Model Weights in Linearized-Attention Transformers


- TransNormerLLM: A Faster and Better Large Language Model with Improved TransNormer (Lightning Attention-1)
- Lightning Attention-2: A Free Lunch for Handling Unlimited Sequence Lengths in Large Language Models


- Attention-Free Transformers
- [RWKV: Reinventing RNNs for the Transformer Era](https://arxiv.org/abs/2305.13048)



# Attention Optimization

- FlashTransformers
- I/O Complexity of Attention, or How Optimal is FlashAttention?