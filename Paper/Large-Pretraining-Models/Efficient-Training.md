# Quantization Training
- SDP4Bit: Toward 4-bit Communication Quantization in Sharded Data Parallelism for LLM Training
- Language Models as Zero-shot Lossless Gradient Compressors: Towards General Neural Parameter Prior Models