# Quantization

- Q-ViT: Accurate and Fully Quantized Low-bit Vision Transformer
- XTC: Extreme Compression for Pre-trained Transformers Made Simple and Efficient
- BiT: Robustly Binarized Multi-distilled Transformer
- LLM.int8(): 8-bit Matrix Multiplication for Transformers at Scale
- Understanding INT4 Quantization for Transformer Models: Latency Speedup, Composability, and Failure Cases
- OPTQ: Accurate Quantization for Generative Pre-trained Transformers
- QLoRA: Efficient Finetuning of Quantized LLMs